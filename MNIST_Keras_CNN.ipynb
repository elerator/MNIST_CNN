{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Now you can zoom\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "class MNIST():\n",
    "    def __init__(self, directory):\n",
    "        self._directory = directory\n",
    "        \n",
    "        self._training_data = self._load_binaries(\"train-images.idx3-ubyte\")\n",
    "        self._training_labels = self._load_binaries(\"train-labels.idx1-ubyte\")\n",
    "        self._test_data = self._load_binaries(\"t10k-images.idx3-ubyte\")\n",
    "        self._test_labels = self._load_binaries(\"t10k-labels.idx1-ubyte\")\n",
    "        \n",
    "        np.random.seed(0)\n",
    "        samples_n = self._training_labels.shape[0]\n",
    "        random_indices = np.random.choice(samples_n, samples_n // 10, replace = False)\n",
    "        np.random.seed()\n",
    "        \n",
    "        self._validation_data = self._training_data[random_indices]\n",
    "        self._validation_labels = self._training_labels[random_indices]\n",
    "        self._training_data = np.delete(self._training_data, random_indices, axis = 0)\n",
    "        self._training_labels = np.delete(self._training_labels, random_indices)\n",
    "    \n",
    "    def _load_binaries(self, file_name):\n",
    "        path = os.path.join(self._directory, file_name)\n",
    "        \n",
    "        with open(path, 'rb') as fd:\n",
    "            check, items_n = struct.unpack(\">ii\", fd.read(8))\n",
    "\n",
    "            if \"images\" in file_name and check == 2051:\n",
    "                height, width = struct.unpack(\">II\", fd.read(8))\n",
    "                images = np.fromfile(fd, dtype = 'uint8')\n",
    "                return np.reshape(images, (items_n, height, width))\n",
    "            elif \"labels\" in file_name and check == 2049:\n",
    "                return np.fromfile(fd, dtype = 'uint8')\n",
    "            else:\n",
    "                raise ValueError(\"Not a MNIST file: \" + path)\n",
    "    \n",
    "    \n",
    "    def get_training_batch(self, batch_size):\n",
    "        return self._get_batch(self._training_data, self._training_labels, batch_size)\n",
    "    \n",
    "    def get_validation_batch(self, batch_size):\n",
    "        return self._get_batch(self._validation_data, self._validation_labels, batch_size)\n",
    "    \n",
    "    def get_test_batch(self, batch_size):\n",
    "        return self._get_batch(self._test_data, self._test_labels, batch_size)\n",
    "    \n",
    "    def _get_batch(self, data, labels, batch_size):\n",
    "        samples_n = labels.shape[0]\n",
    "        if batch_size <= 0:\n",
    "            batch_size = samples_n\n",
    "        \n",
    "        random_indices = np.random.choice(samples_n, samples_n, replace = False)\n",
    "        data = data[random_indices]\n",
    "        labels = labels[random_indices]\n",
    "        for i in range(samples_n // batch_size):\n",
    "            on = i * batch_size\n",
    "            off = on + batch_size\n",
    "            yield data[on:off], labels[on:off]\n",
    "    \n",
    "    \n",
    "    def get_sizes(self):\n",
    "        training_samples_n = self._training_labels.shape[0]\n",
    "        validation_samples_n = self._validation_labels.shape[0]\n",
    "        test_samples_n = self._test_labels.shape[0]\n",
    "        return training_samples_n, validation_samples_n, test_samples_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "import os\n",
    "epochs = 1 #Repeat training with same dataset\n",
    "batch_size = 10#divide dataset in batches of this size for training\n",
    "learning_rate = .01\n",
    "\n",
    "input_size = 28\n",
    "mnist = MNIST(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 28, 28, 16)\n",
      "(None, 26, 26, 32)\n",
      "(None, 13, 13, 32)\n",
      "(None, 13, 13, 32)\n",
      "(None, 5408)\n",
      "(None, 512)\n",
      "(None, 512)\n",
      "(None, 10)\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()#Make sure that memory is freed when loading multiple times\n",
    "tf.reset_default_graph()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), input_shape=(28, 28, 1), padding = \"SAME\", activation = \"tanh\"))\n",
    "model.add(Conv2D(32, (3, 3), activation='tanh'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 28, 28, 16)\n",
      "(None, 26, 26, 32)\n",
      "(None, 13, 13, 32)\n",
      "(None, 13, 13, 32)\n",
      "(None, 5408)\n",
      "(None, 512)\n",
      "(None, 512)\n",
      "(None, 10)\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "tf.reset_default_graph()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), input_shape=(28, 28, 1), padding = \"SAME\", activation = \"relu\"))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer.output_shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(lr=0.1),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 26, 26, 32)\n",
      "(None, 24, 24, 64)\n",
      "(None, 12, 12, 64)\n",
      "(None, 12, 12, 64)\n",
      "(None, 9216)\n",
      "(None, 128)\n",
      "(None, 128)\n",
      "(None, 10)\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "tf.reset_default_graph()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adadelta(lr=0.1),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 50s 2ms/step - loss: 3.3701 - acc: 0.7115\n"
     ]
    }
   ],
   "source": [
    "for batch, label_batch in  MNIST(os.getcwd()).get_training_batch(batch_size = 20000):\n",
    "    #label_batch = keras.utils.to_categorical(label_batch,10)\n",
    "    model.fit(np.expand_dims(batch,axis=3),label_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for batch, label_batch in  MNIST(os.getcwd()).get_training_batch(batch_size = 10000):\n",
    "    label_batch = keras.utils.to_categorical(label_batch,10)\n",
    "    model.fit(np.expand_dims(batch,axis=3),label_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch =  1\n",
      "0.008999999761581421\n",
      "0.8509999918937683\n",
      "0.8669999927282334\n",
      "0.8609999924898147\n",
      "0.8509999969601632\n",
      "0.8679999953508377\n",
      "0.8909999942779541\n",
      "0.8909999912977219\n",
      "0.8649999910593033\n",
      "0.8909999942779541\n",
      "0.8929999941587448\n",
      "0.8969999915361404\n",
      "0.8929999911785126\n",
      "0.8869999921321869\n",
      "0.8859999907016755\n",
      "0.8919999939203263\n",
      "0.9189999926090241\n",
      "0.8909999936819076\n",
      "0.8939999926090241\n",
      "0.898999993801117\n",
      "0.9219999921321869\n",
      "0.9149999904632569\n",
      "0.9049999886751174\n",
      "0.9099999916553497\n",
      "0.9009999924898148\n",
      "0.924999993443489\n",
      "0.922999991774559\n",
      "0.9049999922513962\n",
      "0.9149999928474426\n",
      "0.9369999915361404\n",
      "0.9289999920129776\n",
      "0.9289999932050705\n",
      "0.9159999936819077\n",
      "0.9299999928474426\n",
      "0.9539999932050705\n",
      "0.9269999927282333\n",
      "0.9269999957084656\n",
      "0.9309999924898148\n",
      "0.9179999911785126\n",
      "0.923999993801117\n",
      "0.9399999904632569\n",
      "0.930999995470047\n",
      "0.9249999910593033\n",
      "0.9449999916553498\n",
      "0.9479999929666519\n",
      "0.9359999912977218\n",
      "0.9329999923706055\n",
      "0.9379999923706055\n",
      "0.9449999940395355\n",
      "0.9469999945163727\n",
      "0.9499999928474426\n",
      "0.9319999945163727\n",
      "0.9349999922513962\n",
      "0.9429999941587448\n"
     ]
    }
   ],
   "source": [
    "step = 1\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    print('Epoch = ', epoch + 1)\n",
    "    prelim_acc = 0\n",
    "\n",
    "    for batch, label_batch in mnist.get_training_batch(batch_size = batch_size):\n",
    "        #label_batch = keras.utils.to_categorical(label_batch,10)\n",
    "        stat = model.fit(np.expand_dims(batch,axis=3),label_batch, verbose = 0)#verbose =0 supresses output\n",
    "        \n",
    "        prelim_acc += stat.history[\"acc\"][0]\n",
    "\n",
    "        if (epoch % 100)==0:\n",
    "            print(prelim_acc/100)\n",
    "            prelim_acc = 0\n",
    "        \n",
    "        epoch+=1\n",
    "        #K.clear_session()\n",
    "        #tf.reset_default_graph()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 481us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08044605163740925, 0.977]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_source, test_target = next(mnist.get_validation_batch(batch_size = 1000))\n",
    "model.evaluate(np.expand_dims(test_source,axis=3),test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 28, 28, 16)\n",
      "(?, 14, 14, 16)\n",
      "(?, 14, 14, 32)\n",
      "(?, 7, 7, 32)\n",
      "(?, 1568)\n",
      "(?, 512)\n",
      "(?, 10)\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "learning_rate = 1e-4\n",
    "\n",
    "with graph.as_default():#Override default graph if running cell multiple times\n",
    "    input_layer = tf.placeholder(tf.float32, shape = [None, input_size, input_size])\n",
    "    input_layer1 = tf.expand_dims(input_layer,3)\n",
    "    labels = tf.placeholder(tf.int64, shape = [None])\n",
    "    #print(input_layer1.shape)\n",
    "    \n",
    "    with tf.variable_scope(\"CNN_and_maxpool_1\"):\n",
    "        kernels_1 = tf.Variable(tf.truncated_normal([5, 5, 1, 16], stddev = 0.1))\n",
    "        convolution_1 = tf.nn.conv2d(input_layer1, kernels_1, strides = [1, 1, 1, 1], padding = \"SAME\")\n",
    "        \n",
    "        biases_1 = tf.Variable(tf.constant(0.0, shape = [16]))\n",
    "        feature_maps_1 = tf.nn.tanh(convolution_1 + biases_1)\n",
    "        pool_1 = tf.nn.max_pool(feature_maps_1, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = \"SAME\")\n",
    "    \n",
    "    print(feature_maps_1.shape)\n",
    "    print(pool_1.shape)    \n",
    "    with tf.variable_scope(\"CNN_and_maxpool_2\"):\n",
    "        kernels_2 = tf.Variable(tf.truncated_normal([3, 3, 16, 32], stddev = 0.1))\n",
    "        convolution_2 = tf.nn.conv2d(pool_1, kernels_2, strides = [1, 1, 1, 1], padding = \"SAME\")\n",
    "        biases_2 = tf.Variable(tf.constant(0.0, shape = [32]))\n",
    "        feature_maps_2 = tf.nn.tanh(convolution_2 + biases_2)\n",
    "        pool_2 = tf.nn.max_pool(feature_maps_2, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = \"SAME\")\n",
    "    \n",
    "    print(feature_maps_2.shape)\n",
    "    print(pool_2.shape)\n",
    "    \n",
    "    with tf.variable_scope(\"Fully_connected_layers\"):\n",
    "        flattened = tf.reshape(pool_2, [-1, 7*7*32 ]) ##TO BE ADJUSTED: MUST MATCH NUMBER OF NEUROS OF PREVIOUS layer\n",
    "        print(str(flattened.shape))\n",
    "\n",
    "        weights_3 = tf.Variable(tf.truncated_normal([7*7*32, 512], stddev = 2048**(-1/2)))#TO BE ADJUSTED\n",
    "        biases_3 = tf.Variable(tf.constant(0.0, shape = [512]))\n",
    "        hidden_layer = tf.nn.tanh(tf.matmul(flattened, weights_3) + biases_3)\n",
    "        print(hidden_layer.shape)\n",
    "\n",
    "        weights_4 = tf.Variable(tf.truncated_normal([512, 10], stddev = 512**(-1/2)))\n",
    "        biases_4 = tf.Variable(tf.constant(0.0, shape = [10]))\n",
    "        output_layer_logits = tf.matmul(hidden_layer, weights_4) + biases_4\n",
    "        label = tf.argmax(output_layer_logits,1)\n",
    "\n",
    "        print(output_layer_logits.shape)\n",
    "\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = labels, logits = output_layer_logits)\n",
    "        cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    with tf.variable_scope(\"Optimizer\"):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        optimization_step = optimizer.minimize(cross_entropy)\n",
    "    \n",
    "    with tf.variable_scope(\"Accuracy\"):\n",
    "        accuracy = tf.equal(tf.argmax(tf.nn.softmax(output_layer_logits), 1), labels)\n",
    "        accuracy = tf.reduce_mean(tf.cast(accuracy, tf.float32))\n",
    "        \n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_accuracy(steps = 10, mode = \"validation\"):\n",
    "    #Here we do the forward step 10 times and return the average accuracy\n",
    "    prelim_mean = 0.0\n",
    "    _accuracy = 0.0\n",
    "    step = 0\n",
    "    \n",
    "    if mode == \"validation\":\n",
    "        batches = mnist.get_validation_batch(batch_size)\n",
    "    if mode == \"test\":\n",
    "        batches = mnist.get_test_batch(batch_size)\n",
    "        \n",
    "    for batch, label_batch in mnist.get_training_batch(batch_size):\n",
    "\n",
    "            _accuracy, _ = session.run(\n",
    "                [accuracy, optimization_step],\n",
    "                    feed_dict = {\n",
    "                        input_layer: batch,\n",
    "                        labels : label_batch\n",
    "                    }\n",
    "                )\n",
    "            #summery_file_writer.add_summary(_summary, step) #write summary to file\n",
    "            step += 1\n",
    "            prelim_mean += _accuracy\n",
    "            if step == steps:\n",
    "                return prelim_mean/step\n",
    "    return prelim_mean/step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch =  1\n",
      "Step = 50; Accuracy = 0.6900000035762787\n",
      "Step = 100; Accuracy = 0.7899999916553497\n",
      "Step = 150; Accuracy = 0.8899999916553497\n",
      "Step = 200; Accuracy = 0.8799999833106995\n",
      "Step = 250; Accuracy = 0.8699999988079071\n",
      "Step = 300; Accuracy = 0.9399999856948853\n",
      "Step = 350; Accuracy = 0.9199999928474426\n",
      "Step = 400; Accuracy = 0.9199999928474426\n",
      "Step = 450; Accuracy = 0.949999988079071\n",
      "Step = 500; Accuracy = 0.9199999809265137\n",
      "Step = 550; Accuracy = 0.8899999976158142\n",
      "Step = 600; Accuracy = 0.8999999940395356\n",
      "Step = 650; Accuracy = 0.9499999940395355\n",
      "Step = 700; Accuracy = 0.9099999904632569\n",
      "Step = 750; Accuracy = 0.949999988079071\n",
      "Step = 800; Accuracy = 0.9300000011920929\n",
      "Step = 850; Accuracy = 0.9799999952316284\n",
      "Step = 900; Accuracy = 0.9399999916553498\n",
      "Step = 950; Accuracy = 0.9699999988079071\n",
      "Step = 1000; Accuracy = 0.9399999916553498\n",
      "Step = 1050; Accuracy = 0.949999988079071\n",
      "Step = 1100; Accuracy = 0.9499999940395355\n",
      "Step = 1150; Accuracy = 0.9599999964237214\n",
      "Step = 1200; Accuracy = 0.9799999952316284\n",
      "Step = 1250; Accuracy = 0.9499999940395355\n",
      "Step = 1300; Accuracy = 0.9399999916553498\n",
      "Step = 1350; Accuracy = 0.9799999952316284\n",
      "Step = 1400; Accuracy = 0.9699999928474426\n",
      "Step = 1450; Accuracy = 0.9799999952316284\n",
      "Step = 1500; Accuracy = 0.9599999964237214\n",
      "Step = 1550; Accuracy = 0.95\n",
      "Step = 1600; Accuracy = 0.9899999976158143\n",
      "Step = 1650; Accuracy = 0.9599999964237214\n",
      "Step = 1700; Accuracy = 0.9699999988079071\n",
      "Step = 1750; Accuracy = 0.9599999904632568\n",
      "Step = 1800; Accuracy = 0.9599999904632568\n",
      "Step = 1850; Accuracy = 0.9699999928474426\n",
      "Step = 1900; Accuracy = 0.9799999952316284\n",
      "Step = 1950; Accuracy = 0.9499999940395355\n",
      "Step = 2000; Accuracy = 0.9599999904632568\n",
      "Step = 2050; Accuracy = 0.9599999904632568\n",
      "Step = 2100; Accuracy = 0.9699999988079071\n",
      "Step = 2150; Accuracy = 0.9799999952316284\n",
      "Step = 2200; Accuracy = 1.0\n",
      "Step = 2250; Accuracy = 0.95\n",
      "Step = 2300; Accuracy = 0.9699999928474426\n",
      "Step = 2350; Accuracy = 0.9800000011920929\n",
      "Step = 2400; Accuracy = 0.9799999952316284\n",
      "Step = 2450; Accuracy = 0.9699999988079071\n",
      "Step = 2500; Accuracy = 0.9799999952316284\n",
      "Step = 2550; Accuracy = 0.9699999928474426\n",
      "Step = 2600; Accuracy = 0.9599999964237214\n",
      "Step = 2650; Accuracy = 0.9799999952316284\n",
      "Step = 2700; Accuracy = 1.0\n",
      "Step = 2750; Accuracy = 0.9699999928474426\n",
      "Step = 2800; Accuracy = 0.9599999964237214\n",
      "Step = 2850; Accuracy = 0.9599999904632568\n",
      "Step = 2900; Accuracy = 0.9799999952316284\n",
      "Step = 2950; Accuracy = 0.9799999952316284\n",
      "Step = 3000; Accuracy = 0.9899999976158143\n",
      "Step = 3050; Accuracy = 0.9499999940395355\n",
      "Step = 3100; Accuracy = 0.9599999904632568\n",
      "Step = 3150; Accuracy = 0.9399999916553498\n",
      "Step = 3200; Accuracy = 0.9899999976158143\n",
      "Step = 3250; Accuracy = 0.9799999952316284\n",
      "Step = 3300; Accuracy = 0.9299999892711639\n",
      "Step = 3350; Accuracy = 0.9899999976158143\n",
      "Step = 3400; Accuracy = 0.9899999976158143\n",
      "Step = 3450; Accuracy = 0.9599999904632568\n",
      "Step = 3500; Accuracy = 0.949999988079071\n",
      "Step = 3550; Accuracy = 0.949999988079071\n",
      "Step = 3600; Accuracy = 0.9699999928474426\n",
      "Step = 3650; Accuracy = 0.9799999952316284\n",
      "Step = 3700; Accuracy = 0.9599999964237214\n",
      "Step = 3750; Accuracy = 0.9899999976158143\n",
      "Step = 3800; Accuracy = 0.9299999952316285\n",
      "Step = 3850; Accuracy = 0.9800000011920929\n",
      "Step = 3900; Accuracy = 0.9699999928474426\n",
      "Step = 3950; Accuracy = 0.9799999952316284\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    session = tf.InteractiveSession()\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    step = 1\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        print('Epoch = ', epoch + 1)\n",
    "        \n",
    "        for batch, label_batch in mnist.get_training_batch(batch_size = batch_size):\n",
    "            _accuracy, _ = session.run([accuracy, optimization_step],feed_dict = { input_layer: batch,labels : label_batch })\n",
    "                \n",
    "            step += 1                                \n",
    "            if ((step % 50)==0):\n",
    "                validation_accuracy = mean_accuracy(10)\n",
    "                print('Step = ' + str(step) + '; Accuracy = ' + str(validation_accuracy))\n",
    "\n",
    "    \n",
    "    #Test accuracy\n",
    "    test_accuracy = mean_accuracy(-1,\"test\")\n",
    "    print(\"\\n Test accuracy = \" + str(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path: /tmp/model3.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    save_path = saver.save(session, \"/tmp/model3.ckpt\")\n",
    "    print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/eler/miniconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model3.ckpt\n",
      "Model restored.\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Create some variables.\n",
    "v1 = tf.get_variable(\"v1\", shape=[3])\n",
    "v2 = tf.get_variable(\"v2\", shape=[5])\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(session, \"/tmp/model3.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    pic = mnist.get_test_batch(1)\n",
    "    pic = next(pic)[0]\n",
    "    plt.imshow(pic[0,:,:])\n",
    "    prediction = session.run([label],feed_dict = {input_layer: pic})\n",
    "    print(prediction[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
