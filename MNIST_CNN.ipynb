{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Now you can zoom\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "class MNIST():\n",
    "    def __init__(self, directory):\n",
    "        self._directory = directory\n",
    "        \n",
    "        self._training_data = self._load_binaries(\"train-images.idx3-ubyte\")\n",
    "        self._training_labels = self._load_binaries(\"train-labels.idx1-ubyte\")\n",
    "        self._test_data = self._load_binaries(\"t10k-images.idx3-ubyte\")\n",
    "        self._test_labels = self._load_binaries(\"t10k-labels.idx1-ubyte\")\n",
    "        \n",
    "        np.random.seed(0)\n",
    "        samples_n = self._training_labels.shape[0]\n",
    "        random_indices = np.random.choice(samples_n, samples_n // 10, replace = False)\n",
    "        np.random.seed()\n",
    "        \n",
    "        self._validation_data = self._training_data[random_indices]\n",
    "        self._validation_labels = self._training_labels[random_indices]\n",
    "        self._training_data = np.delete(self._training_data, random_indices, axis = 0)\n",
    "        self._training_labels = np.delete(self._training_labels, random_indices)\n",
    "    \n",
    "    def _load_binaries(self, file_name):\n",
    "        path = os.path.join(self._directory, file_name)\n",
    "        \n",
    "        with open(path, 'rb') as fd:\n",
    "            check, items_n = struct.unpack(\">ii\", fd.read(8))\n",
    "\n",
    "            if \"images\" in file_name and check == 2051:\n",
    "                height, width = struct.unpack(\">II\", fd.read(8))\n",
    "                images = np.fromfile(fd, dtype = 'uint8')\n",
    "                return np.reshape(images, (items_n, height, width))\n",
    "            elif \"labels\" in file_name and check == 2049:\n",
    "                return np.fromfile(fd, dtype = 'uint8')\n",
    "            else:\n",
    "                raise ValueError(\"Not a MNIST file: \" + path)\n",
    "    \n",
    "    \n",
    "    def get_training_batch(self, batch_size):\n",
    "        return self._get_batch(self._training_data, self._training_labels, batch_size)\n",
    "    \n",
    "    def get_validation_batch(self, batch_size):\n",
    "        return self._get_batch(self._validation_data, self._validation_labels, batch_size)\n",
    "    \n",
    "    def get_test_batch(self, batch_size):\n",
    "        return self._get_batch(self._test_data, self._test_labels, batch_size)\n",
    "    \n",
    "    def _get_batch(self, data, labels, batch_size):\n",
    "        samples_n = labels.shape[0]\n",
    "        if batch_size <= 0:\n",
    "            batch_size = samples_n\n",
    "        \n",
    "        random_indices = np.random.choice(samples_n, samples_n, replace = False)\n",
    "        data = data[random_indices]\n",
    "        labels = labels[random_indices]\n",
    "        for i in range(samples_n // batch_size):\n",
    "            on = i * batch_size\n",
    "            off = on + batch_size\n",
    "            yield data[on:off], labels[on:off]\n",
    "    \n",
    "    \n",
    "    def get_sizes(self):\n",
    "        training_samples_n = self._training_labels.shape[0]\n",
    "        validation_samples_n = self._validation_labels.shape[0]\n",
    "        test_samples_n = self._test_labels.shape[0]\n",
    "        return training_samples_n, validation_samples_n, test_samples_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "import os\n",
    "epochs = 1 #Repeat training with same dataset\n",
    "batch_size = 10#divide dataset in batches of this size for training\n",
    "learning_rate = .01\n",
    "\n",
    "input_size = 28\n",
    "mnist = MNIST(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 28, 28, 1)\n",
      "WARNING:tensorflow:From /home/eler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "(?, 28, 28, 16)\n",
      "(?, 14, 14, 16)\n",
      "(?, 14, 14, 32)\n",
      "(?, 7, 7, 32)\n",
      "(?, 1568)\n",
      "(?, 512)\n",
      "(?, 10)\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "learning_rate = 1e-4\n",
    "\n",
    "with graph.as_default():#Override default graph if running cell multiple times\n",
    "    input_layer = tf.placeholder(tf.float32, shape = [None, input_size, input_size])\n",
    "    input_layer1 = tf.expand_dims(input_layer,3)\n",
    "    labels = tf.placeholder(tf.int64, shape = [None])\n",
    "    print(input_layer1.shape)\n",
    "    \n",
    "    with tf.variable_scope(\"CNN_and_maxpool_1\"):\n",
    "        kernels_1 = tf.Variable(tf.truncated_normal([5, 5, 1, 16], stddev = 0.1))\n",
    "        convolution_1 = tf.nn.conv2d(input_layer1, kernels_1, strides = [1, 1, 1, 1], padding = \"SAME\")\n",
    "        \n",
    "        biases_1 = tf.Variable(tf.constant(0.0, shape = [16]))\n",
    "        feature_maps_1 = tf.nn.tanh(convolution_1 + biases_1)\n",
    "        pool_1 = tf.nn.max_pool(feature_maps_1, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = \"SAME\")\n",
    "    \n",
    "    print(feature_maps_1.shape)\n",
    "    print(pool_1.shape)    \n",
    "    with tf.variable_scope(\"CNN_and_maxpool_2\"):\n",
    "        kernels_2 = tf.Variable(tf.truncated_normal([3, 3, 16, 32], stddev = 0.1))\n",
    "        convolution_2 = tf.nn.conv2d(pool_1, kernels_2, strides = [1, 1, 1, 1], padding = \"SAME\")\n",
    "        biases_2 = tf.Variable(tf.constant(0.0, shape = [32]))\n",
    "        feature_maps_2 = tf.nn.tanh(convolution_2 + biases_2)\n",
    "        pool_2 = tf.nn.max_pool(feature_maps_2, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = \"SAME\")\n",
    "    \n",
    "    print(feature_maps_2.shape)\n",
    "    print(pool_2.shape)\n",
    "    \n",
    "    with tf.variable_scope(\"Fully_connected_layers\"):\n",
    "        flattened = tf.reshape(pool_2, [-1, 7*7*32 ]) ##TO BE ADJUSTED: MUST MATCH NUMBER OF NEUROS OF PREVIOUS layer\n",
    "        print(str(flattened.shape))\n",
    "\n",
    "        weights_3 = tf.Variable(tf.truncated_normal([7*7*32, 512], stddev = 2048**(-1/2)))#TO BE ADJUSTED\n",
    "        biases_3 = tf.Variable(tf.constant(0.0, shape = [512]))\n",
    "        hidden_layer = tf.nn.tanh(tf.matmul(flattened, weights_3) + biases_3)\n",
    "        print(hidden_layer.shape)\n",
    "\n",
    "        weights_4 = tf.Variable(tf.truncated_normal([512, 10], stddev = 512**(-1/2)))\n",
    "        biases_4 = tf.Variable(tf.constant(0.0, shape = [10]))\n",
    "        output_layer_logits = tf.matmul(hidden_layer, weights_4) + biases_4\n",
    "        label = tf.argmax(output_layer_logits,1)\n",
    "\n",
    "        print(output_layer_logits.shape)\n",
    "\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = labels, logits = output_layer_logits)\n",
    "        cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    with tf.variable_scope(\"Optimizer\"):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        optimization_step = optimizer.minimize(cross_entropy)\n",
    "    \n",
    "    with tf.variable_scope(\"Accuracy\"):\n",
    "        accuracy = tf.equal(tf.argmax(tf.nn.softmax(output_layer_logits), 1), labels)\n",
    "        accuracy = tf.reduce_mean(tf.cast(accuracy, tf.float32))\n",
    "        \n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_accuracy(steps = 10, mode = \"validation\"):\n",
    "    #Here we do the forward step 10 times and return the average accuracy\n",
    "    prelim_mean = 0.0\n",
    "    _accuracy = 0.0\n",
    "    step = 0\n",
    "    \n",
    "    if mode == \"validation\":\n",
    "        batches = mnist.get_validation_batch(batch_size)\n",
    "    if mode == \"test\":\n",
    "        batches = mnist.get_test_batch(batch_size)\n",
    "        \n",
    "    for batch, label_batch in mnist.get_training_batch(batch_size):\n",
    "\n",
    "            _accuracy, _ = session.run(\n",
    "                [accuracy, optimization_step],\n",
    "                    feed_dict = {\n",
    "                        input_layer: batch,\n",
    "                        labels : label_batch\n",
    "                    }\n",
    "                )\n",
    "            #summery_file_writer.add_summary(_summary, step) #write summary to file\n",
    "            step += 1\n",
    "            prelim_mean += _accuracy\n",
    "            if step == steps:\n",
    "                return prelim_mean/step\n",
    "    return prelim_mean/step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch =  1\n",
      "Step = 50; Accuracy = 0.6900000035762787\n",
      "Step = 100; Accuracy = 0.7899999916553497\n",
      "Step = 150; Accuracy = 0.8899999916553497\n",
      "Step = 200; Accuracy = 0.8799999833106995\n",
      "Step = 250; Accuracy = 0.8699999988079071\n",
      "Step = 300; Accuracy = 0.9399999856948853\n",
      "Step = 350; Accuracy = 0.9199999928474426\n",
      "Step = 400; Accuracy = 0.9199999928474426\n",
      "Step = 450; Accuracy = 0.949999988079071\n",
      "Step = 500; Accuracy = 0.9199999809265137\n",
      "Step = 550; Accuracy = 0.8899999976158142\n",
      "Step = 600; Accuracy = 0.8999999940395356\n",
      "Step = 650; Accuracy = 0.9499999940395355\n",
      "Step = 700; Accuracy = 0.9099999904632569\n",
      "Step = 750; Accuracy = 0.949999988079071\n",
      "Step = 800; Accuracy = 0.9300000011920929\n",
      "Step = 850; Accuracy = 0.9799999952316284\n",
      "Step = 900; Accuracy = 0.9399999916553498\n",
      "Step = 950; Accuracy = 0.9699999988079071\n",
      "Step = 1000; Accuracy = 0.9399999916553498\n",
      "Step = 1050; Accuracy = 0.949999988079071\n",
      "Step = 1100; Accuracy = 0.9499999940395355\n",
      "Step = 1150; Accuracy = 0.9599999964237214\n",
      "Step = 1200; Accuracy = 0.9799999952316284\n",
      "Step = 1250; Accuracy = 0.9499999940395355\n",
      "Step = 1300; Accuracy = 0.9399999916553498\n",
      "Step = 1350; Accuracy = 0.9799999952316284\n",
      "Step = 1400; Accuracy = 0.9699999928474426\n",
      "Step = 1450; Accuracy = 0.9799999952316284\n",
      "Step = 1500; Accuracy = 0.9599999964237214\n",
      "Step = 1550; Accuracy = 0.95\n",
      "Step = 1600; Accuracy = 0.9899999976158143\n",
      "Step = 1650; Accuracy = 0.9599999964237214\n",
      "Step = 1700; Accuracy = 0.9699999988079071\n",
      "Step = 1750; Accuracy = 0.9599999904632568\n",
      "Step = 1800; Accuracy = 0.9599999904632568\n",
      "Step = 1850; Accuracy = 0.9699999928474426\n",
      "Step = 1900; Accuracy = 0.9799999952316284\n",
      "Step = 1950; Accuracy = 0.9499999940395355\n",
      "Step = 2000; Accuracy = 0.9599999904632568\n",
      "Step = 2050; Accuracy = 0.9599999904632568\n",
      "Step = 2100; Accuracy = 0.9699999988079071\n",
      "Step = 2150; Accuracy = 0.9799999952316284\n",
      "Step = 2200; Accuracy = 1.0\n",
      "Step = 2250; Accuracy = 0.95\n",
      "Step = 2300; Accuracy = 0.9699999928474426\n",
      "Step = 2350; Accuracy = 0.9800000011920929\n",
      "Step = 2400; Accuracy = 0.9799999952316284\n",
      "Step = 2450; Accuracy = 0.9699999988079071\n",
      "Step = 2500; Accuracy = 0.9799999952316284\n",
      "Step = 2550; Accuracy = 0.9699999928474426\n",
      "Step = 2600; Accuracy = 0.9599999964237214\n",
      "Step = 2650; Accuracy = 0.9799999952316284\n",
      "Step = 2700; Accuracy = 1.0\n",
      "Step = 2750; Accuracy = 0.9699999928474426\n",
      "Step = 2800; Accuracy = 0.9599999964237214\n",
      "Step = 2850; Accuracy = 0.9599999904632568\n",
      "Step = 2900; Accuracy = 0.9799999952316284\n",
      "Step = 2950; Accuracy = 0.9799999952316284\n",
      "Step = 3000; Accuracy = 0.9899999976158143\n",
      "Step = 3050; Accuracy = 0.9499999940395355\n",
      "Step = 3100; Accuracy = 0.9599999904632568\n",
      "Step = 3150; Accuracy = 0.9399999916553498\n",
      "Step = 3200; Accuracy = 0.9899999976158143\n",
      "Step = 3250; Accuracy = 0.9799999952316284\n",
      "Step = 3300; Accuracy = 0.9299999892711639\n",
      "Step = 3350; Accuracy = 0.9899999976158143\n",
      "Step = 3400; Accuracy = 0.9899999976158143\n",
      "Step = 3450; Accuracy = 0.9599999904632568\n",
      "Step = 3500; Accuracy = 0.949999988079071\n",
      "Step = 3550; Accuracy = 0.949999988079071\n",
      "Step = 3600; Accuracy = 0.9699999928474426\n",
      "Step = 3650; Accuracy = 0.9799999952316284\n",
      "Step = 3700; Accuracy = 0.9599999964237214\n",
      "Step = 3750; Accuracy = 0.9899999976158143\n",
      "Step = 3800; Accuracy = 0.9299999952316285\n",
      "Step = 3850; Accuracy = 0.9800000011920929\n",
      "Step = 3900; Accuracy = 0.9699999928474426\n",
      "Step = 3950; Accuracy = 0.9799999952316284\n",
      "Step = 4000; Accuracy = 0.9899999976158143\n",
      "Step = 4050; Accuracy = 0.9599999964237214\n",
      "Step = 4100; Accuracy = 0.9699999928474426\n",
      "Step = 4150; Accuracy = 0.9899999976158143\n",
      "Step = 4200; Accuracy = 0.9399999916553498\n",
      "Step = 4250; Accuracy = 0.9799999952316284\n",
      "Step = 4300; Accuracy = 0.9899999976158143\n",
      "Step = 4350; Accuracy = 0.9899999976158143\n",
      "Step = 4400; Accuracy = 0.9899999976158143\n",
      "Step = 4450; Accuracy = 0.9899999976158143\n",
      "Step = 4500; Accuracy = 1.0\n",
      "Step = 4550; Accuracy = 0.9799999952316284\n",
      "Step = 4600; Accuracy = 1.0\n",
      "Step = 4650; Accuracy = 0.9699999928474426\n",
      "Step = 4700; Accuracy = 0.9699999928474426\n",
      "Step = 4750; Accuracy = 0.9799999952316284\n",
      "Step = 4800; Accuracy = 0.9399999916553498\n",
      "Step = 4850; Accuracy = 0.9599999904632568\n",
      "Step = 4900; Accuracy = 0.9799999952316284\n",
      "Step = 4950; Accuracy = 1.0\n",
      "Step = 5000; Accuracy = 0.9699999928474426\n",
      "Step = 5050; Accuracy = 0.9799999952316284\n",
      "Step = 5100; Accuracy = 0.9899999976158143\n",
      "Step = 5150; Accuracy = 0.9600000023841858\n",
      "Step = 5200; Accuracy = 0.9599999904632568\n",
      "Step = 5250; Accuracy = 0.9799999952316284\n",
      "Step = 5300; Accuracy = 0.9799999952316284\n",
      "Step = 5350; Accuracy = 0.9499999940395355\n",
      "Step = 5400; Accuracy = 0.9599999964237214\n",
      "\n",
      " Test accuracy = 0.9810555518446146\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    session = tf.InteractiveSession()\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    step = 1\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        print('Epoch = ', epoch + 1)\n",
    "        \n",
    "        for batch, label_batch in mnist.get_training_batch(batch_size = batch_size):\n",
    "            _accuracy, _ = session.run([accuracy, optimization_step],feed_dict = { input_layer: batch,labels : label_batch })\n",
    "                \n",
    "            step += 1                                \n",
    "            if ((step % 50)==0):\n",
    "                validation_accuracy = mean_accuracy(10)\n",
    "                print('Step = ' + str(step) + '; Accuracy = ' + str(validation_accuracy))\n",
    "\n",
    "    \n",
    "    #Test accuracy\n",
    "    test_accuracy = mean_accuracy(-1,\"test\")\n",
    "    print(\"\\n Test accuracy = \" + str(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path: /tmp/model3.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    save_path = saver.save(session, \"/tmp/model3.ckpt\")\n",
    "    print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/eler/miniconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model3.ckpt\n",
      "Model restored.\n",
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Create some variables.\n",
    "v1 = tf.get_variable(\"v1\", shape=[3])\n",
    "v2 = tf.get_variable(\"v2\", shape=[5])\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(session, \"/tmp/model3.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    pic = mnist.get_test_batch(1)\n",
    "    pic = next(pic)[0]\n",
    "    plt.imshow(pic[0,:,:])\n",
    "    prediction = session.run([label],feed_dict = {input_layer: pic})\n",
    "    print(prediction[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
